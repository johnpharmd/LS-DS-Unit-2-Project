{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha: initial import statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.preprocessing import minmax_scale as mms\n",
    "# !pip install category_encoders\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm.libsvm import predict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59400, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>...</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2011-03-14</td>\n",
       "      <td>Roman</td>\n",
       "      <td>1390</td>\n",
       "      <td>Roman</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>annually</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-03-06</td>\n",
       "      <td>Grumeti</td>\n",
       "      <td>1399</td>\n",
       "      <td>GRUMETI</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>Zahanati</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2013-02-25</td>\n",
       "      <td>Lottery Club</td>\n",
       "      <td>686</td>\n",
       "      <td>World vision</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>Kwa Mahundi</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>per bucket</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>dam</td>\n",
       "      <td>dam</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-28</td>\n",
       "      <td>Unicef</td>\n",
       "      <td>263</td>\n",
       "      <td>UNICEF</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>Zahanati Ya Nanyumbu</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>dry</td>\n",
       "      <td>machine dbh</td>\n",
       "      <td>borehole</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-07-13</td>\n",
       "      <td>Action In A</td>\n",
       "      <td>0</td>\n",
       "      <td>Artisan</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>Shuleni</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  amount_tsh date_recorded        funder  gps_height     installer  \\\n",
       "0  69572      6000.0    2011-03-14         Roman        1390         Roman   \n",
       "1   8776         0.0    2013-03-06       Grumeti        1399       GRUMETI   \n",
       "2  34310        25.0    2013-02-25  Lottery Club         686  World vision   \n",
       "3  67743         0.0    2013-01-28        Unicef         263        UNICEF   \n",
       "4  19728         0.0    2011-07-13   Action In A           0       Artisan   \n",
       "\n",
       "   longitude   latitude              wpt_name  num_private  ... payment_type  \\\n",
       "0  34.938093  -9.856322                  none            0  ...     annually   \n",
       "1  34.698766  -2.147466              Zahanati            0  ...    never pay   \n",
       "2  37.460664  -3.821329           Kwa Mahundi            0  ...   per bucket   \n",
       "3  38.486161 -11.155298  Zahanati Ya Nanyumbu            0  ...    never pay   \n",
       "4  31.130847  -1.825359               Shuleni            0  ...    never pay   \n",
       "\n",
       "  water_quality quality_group      quantity  quantity_group  \\\n",
       "0          soft          good        enough          enough   \n",
       "1          soft          good  insufficient    insufficient   \n",
       "2          soft          good        enough          enough   \n",
       "3          soft          good           dry             dry   \n",
       "4          soft          good      seasonal        seasonal   \n",
       "\n",
       "                 source           source_type  source_class  \\\n",
       "0                spring                spring   groundwater   \n",
       "1  rainwater harvesting  rainwater harvesting       surface   \n",
       "2                   dam                   dam       surface   \n",
       "3           machine dbh              borehole   groundwater   \n",
       "4  rainwater harvesting  rainwater harvesting       surface   \n",
       "\n",
       "               waterpoint_type waterpoint_type_group  \n",
       "0           communal standpipe    communal standpipe  \n",
       "1           communal standpipe    communal standpipe  \n",
       "2  communal standpipe multiple    communal standpipe  \n",
       "3  communal standpipe multiple    communal standpipe  \n",
       "4           communal standpipe    communal standpipe  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bravo: give background, then load and inspect data\n",
    "# here's a URL for background: https://www.kaggle.com/t/32b89e93d8a44743983a0ab1c19c85f3\n",
    "# Q: \"Can you predict which [Tanzanian] water pumps are faulty?\"\n",
    "# H_null: something like \"all features are equally likely to make H2O unclean and/or non-potable\"\n",
    "# H_one: akin to \"one or a group of features enables high-accuracy prediction of faulty pumps\"\n",
    "\n",
    "kaggle_path = 'C:\\\\Users\\\\jhump\\\\Desktop\\\\Desktop_professional\\\\LSDS\\\\Full_Course\\\\train_features.csv'\n",
    "\n",
    "df = pd.read_csv(kaggle_path)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59400 entries, 0 to 59399\n",
      "Data columns (total 40 columns):\n",
      "id                       59400 non-null int64\n",
      "amount_tsh               59400 non-null float64\n",
      "date_recorded            59400 non-null object\n",
      "funder                   55765 non-null object\n",
      "gps_height               59400 non-null int64\n",
      "installer                55745 non-null object\n",
      "longitude                59400 non-null float64\n",
      "latitude                 59400 non-null float64\n",
      "wpt_name                 59400 non-null object\n",
      "num_private              59400 non-null int64\n",
      "basin                    59400 non-null object\n",
      "subvillage               59029 non-null object\n",
      "region                   59400 non-null object\n",
      "region_code              59400 non-null int64\n",
      "district_code            59400 non-null int64\n",
      "lga                      59400 non-null object\n",
      "ward                     59400 non-null object\n",
      "population               59400 non-null int64\n",
      "public_meeting           56066 non-null object\n",
      "recorded_by              59400 non-null object\n",
      "scheme_management        55523 non-null object\n",
      "scheme_name              31234 non-null object\n",
      "permit                   56344 non-null object\n",
      "construction_year        59400 non-null int64\n",
      "extraction_type          59400 non-null object\n",
      "extraction_type_group    59400 non-null object\n",
      "extraction_type_class    59400 non-null object\n",
      "management               59400 non-null object\n",
      "management_group         59400 non-null object\n",
      "payment                  59400 non-null object\n",
      "payment_type             59400 non-null object\n",
      "water_quality            59400 non-null object\n",
      "quality_group            59400 non-null object\n",
      "quantity                 59400 non-null object\n",
      "quantity_group           59400 non-null object\n",
      "source                   59400 non-null object\n",
      "source_type              59400 non-null object\n",
      "source_class             59400 non-null object\n",
      "waterpoint_type          59400 non-null object\n",
      "waterpoint_type_group    59400 non-null object\n",
      "dtypes: float64(3), int64(7), object(30)\n",
      "memory usage: 18.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "amount_tsh                   0\n",
       "date_recorded                0\n",
       "funder                    3635\n",
       "gps_height                   0\n",
       "installer                 3655\n",
       "longitude                    0\n",
       "latitude                     0\n",
       "wpt_name                     0\n",
       "num_private                  0\n",
       "basin                        0\n",
       "subvillage                 371\n",
       "region                       0\n",
       "region_code                  0\n",
       "district_code                0\n",
       "lga                          0\n",
       "ward                         0\n",
       "population                   0\n",
       "public_meeting            3334\n",
       "recorded_by                  0\n",
       "scheme_management         3877\n",
       "scheme_name              28166\n",
       "permit                    3056\n",
       "construction_year            0\n",
       "extraction_type              0\n",
       "extraction_type_group        0\n",
       "extraction_type_class        0\n",
       "management                   0\n",
       "management_group             0\n",
       "payment                      0\n",
       "payment_type                 0\n",
       "water_quality                0\n",
       "quality_group                0\n",
       "quantity                     0\n",
       "quantity_group               0\n",
       "source                       0\n",
       "source_type                  0\n",
       "source_class                 0\n",
       "waterpoint_type              0\n",
       "waterpoint_type_group        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# charlie: check data for nan's\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{dtype('int64'): Index(['id', 'gps_height', 'num_private', 'region_code', 'district_code',\n",
       "        'population', 'construction_year'],\n",
       "       dtype='object'),\n",
       " dtype('float64'): Index(['amount_tsh', 'longitude', 'latitude'], dtype='object'),\n",
       " dtype('O'): Index(['date_recorded', 'funder', 'installer', 'wpt_name', 'basin',\n",
       "        'subvillage', 'region', 'lga', 'ward', 'public_meeting', 'recorded_by',\n",
       "        'scheme_management', 'scheme_name', 'permit', 'extraction_type',\n",
       "        'extraction_type_group', 'extraction_type_class', 'management',\n",
       "        'management_group', 'payment', 'payment_type', 'water_quality',\n",
       "        'quality_group', 'quantity', 'quantity_group', 'source', 'source_type',\n",
       "        'source_class', 'waterpoint_type', 'waterpoint_type_group'],\n",
       "       dtype='object')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.copy()\n",
    "\n",
    "# source for following: https://stackoverflow.com/questions/22470690/get-list-of-pandas-dataframe-columns-based-on-data-type\n",
    "df1_dtype_groups = df1.columns.to_series().groupby(df1.dtypes).groups\n",
    "df1_dtype_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['soft', 'salty', 'milky', 'unknown', 'fluoride', 'coloured',\n",
       "       'salty abandoned', 'fluoride abandoned'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what features will show whether or not H2O is clean and potable?\n",
    "# let's investigate 'water_quality'\n",
    "df1.water_quality.unique()  # questions: merge both 'abandoned' strings into one? what to do with 'unknown'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta: preprocess data\n",
    "# CREDIT for this function, to Ryan Herr/LSDS\n",
    "\n",
    "def train_validation_test_split(X, y, train_size=0.8, val_size=0.1, test_size=0.1, \n",
    "                                random_state=None, shuffle=True):\n",
    "    assert train_size + val_size + test_size == 1\n",
    "    \n",
    "    X_train_val, X_test, y_train_val, y_test = tts(X, y, test_size=test_size,\n",
    "                                                   random_state=random_state, shuffle=shuffle)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = tts(X_train_val, y_train_val,\n",
    "                                         test_size=val_size/(train_size+val_size), \n",
    "                                         random_state=random_state, shuffle=shuffle)\n",
    "    print('X_train is:', X_train, '\\n')\n",
    "    # train_val_test = [X_train, X_val, X_test, y_train, y_val, y_test]\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# echo: fit, validate, and present model\n",
    "\n",
    "# 2019-02-04 comment: I believe that some sort of advanced regression will be best here, but TBD\n",
    "# for baseline model, X might include 'id', 'region_code', 'population', 'construction_year'\n",
    "# IMPORTANT NOTE: 2019-02-06 0830hrs PST: REFACTOR y\n",
    "\n",
    "train_labels = pd.read_csv('C:\\\\Users\\\\jhump\\\\Desktop\\\\Desktop_professional\\\\LSDS\\\\train_labels.csv')\n",
    "df2 = train_labels.copy()\n",
    "\n",
    "# X = df1[['id', 'region_code', 'population', 'construction_year']]\n",
    "# got much, much lower accuracy score, after refactoring, so will start to 'twiddle' the feature knobs\n",
    "# first, take out 'id' -> accuracy score: slightly increased, at _0.5579545454545455_\n",
    "# X = df1[['region_code', 'population', 'construction_year']]\n",
    "\n",
    "# second, add in 'gps_height' -> accuracy score: not significantly changed\n",
    "# X = df1[['gps_height', 'region_code', 'population', 'construction_year']]\n",
    "\n",
    "# third, take 'gps_height' back out, and take out 'region_code' -> accuracy score: 0.5430134680134681\n",
    "# X = df1[['population', 'construction_year']]\n",
    "# bear this method in mind: X_test_numeric = X_test.select_dtypes(np.number)\n",
    "# KEY: thus, need to add in categorical features--one-hot-encoding as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59400 entries, 0 to 59399\n",
      "Data columns (total 8 columns):\n",
      "id                   59400 non-null int64\n",
      "gps_height           59400 non-null int64\n",
      "num_private          59400 non-null int64\n",
      "region_code          59400 non-null int64\n",
      "district_code        59400 non-null int64\n",
      "population           59400 non-null int64\n",
      "construction_year    59400 non-null int64\n",
      "water_quality        59400 non-null object\n",
      "dtypes: int64(7), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# continue fitting, validating LogReg model\n",
    "# now, after those 3 trials above, will add 'water_quality' to X -> accuracy score:\n",
    "# X = df1[['population', 'construction_year', 'water_quality']]\n",
    "X = df1[['id', 'gps_height', 'num_private', 'region_code', 'district_code',\n",
    "        'population', 'construction_year', 'water_quality']]\n",
    "# call 'mms' on X after creating X namespace\n",
    "# mms(X) -- 2019-02-06 0935hrs: attempting pipeline for first time\n",
    "pd.get_dummies(X)\n",
    "y = df2.status_group\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhump\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jhump\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'salty'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-749d7dad787a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlog_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mlog_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m-> 1285\u001b[1;33m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 756\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    757\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \"\"\"\n\u001b[1;32m--> 501\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'salty'"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = tts(X, y, train_size=0.6, random_state=42)\n",
    "\n",
    "log_reg = LogisticRegression().fit(X, y)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n",
    "# recall: train_val_test = [X_train, X_val, X_test, y_train, y_val, y_test]\n",
    "# pipeline_tvts = train_validation_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline, G-d willing\n",
    "# pipeline = make_pipeline(ce.OneHotEncoder(use_cat_names=True), \n",
    "#                          StandardScaler(), LogisticRegression(solver='lbfgs'))\n",
    "\n",
    "# pipeline.fit(pipeline_tvts)\n",
    "# y_pred = pipeline.predict(X_val)\n",
    "# accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine log_reg and its methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pseudo-random baseline\n",
    "\n",
    "print('id', ',', 'status_group')\n",
    "pumps = X['id']\n",
    "for pump in pumps[:10]:\n",
    "    if random.choice(['not_functional', 'functional']) == 'functional':\n",
    "        print(pump, ',', 'functional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the simple LogReg baseline for Kaggle csv\n",
    "# predicted_non_abandoned_pump_count = 0\n",
    "max_rows = 0\n",
    "\n",
    "print('id', ',', 'status_group')\n",
    "pumps = X_test['id']\n",
    "while max_rows < 14359:\n",
    "    for pump, pred in zip(pumps, y_pred):\n",
    "        if pred != 'unknown' and 'abandoned' not in pred and pred != 'salty':\n",
    "            print(pump, ',', 'functional')\n",
    "            # predicted_non_abandoned_pump_count += 1\n",
    "            max_rows += 1\n",
    "\n",
    "# print('predicted number of unabandoned pumps is:', predicted_non_abandoned_pump_count)\n",
    "print('number of rows generated is:', max_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for further modeling\n",
    "\n",
    "# faulty_pumps = predict(df1.id, kernel='sigmoid', degree=1, coef0=log_reg.coef_)\n",
    "# faulty_pumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write LogReg baseline data to csv on local machine, in preparation to push to GitHub then Kaggle\n",
    "prediction_csv_path = 'C:\\\\Users\\\\jhump\\\\Desktop\\\\Desktop_professional\\\\LSDS\\\\Full_Course\\\\kaggle-prediction.csv'\n",
    "\n",
    "with open(prediction_csv_path, 'w') as infile:\n",
    "    max_rows = 0\n",
    "    infile.write('id' + ', ' + 'status_group' + '\\n')\n",
    "    pumps = X_test['id']\n",
    "    while max_rows < 14359:\n",
    "        for pump, pred in zip(pumps, y_pred):\n",
    "            if 'abandoned' not in pred and 'unknown' not in pred:\n",
    "                infile.write(str(pump) + ', ' + 'functional' + '\\n')\n",
    "                max_rows += 1\n",
    "    infile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt to understand tanzania-data-kaggle.csv vis a vis Kaggle submission req's\n",
    "# command line syntax CREDIT to Ryan Herr/LSDS\n",
    "tanzania_data_kaggle = 'C:\\\\Users\\\\jhump\\\\Desktop\\\\Desktop_professional\\\\LSDS\\\\Full_Course\\\\tanzania-data-kaggle.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019-02-06 Based on feedback from Ryan Herr/LSDS, will refactor y above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foxtrot: analyze and interpret model predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
